


Version: Q425 (November 2025) Owner: Anirban Majumdar, PVN PavanKumar
Contributors: To be updated
Reviewers: CTO Circle CPA WG + SMEs

Preface and Scope 
This document defines the AI-Native North Star Architecture as a high-level vision that guides the design and evolution of SAP’s technology landscape. It outlines the desired end state of how systems, processes, and platform should work together, providing a compass for alignment and consistent architectural decisions. It is not a set of specifications, release schedules, product commitments, or roadmaps, but a guiding framework that offers direction and context across teams. Looking three to five years ahead, it sets the foundation for SAP’s evolution from deterministic systems trusted for decades to AI-native systems that can reason, learn, and anticipate while preserving enterprise trust, compliance, reliability, and global scale.

Unlike earlier versions, this is an online and living document available on the CTO Circle GitHub, where the most recently released version will always be accessible. It will evolve continuously, with updates planned approximately every three months to reflect rapid advances in technology and AI. Revisions and feedback will be managed through the established GitHub workflow to ensure transparency, traceability, and collaboration.

Table of Contents

1. EXECUTIVE SUMMARY	3
2. AI-NATIVE NORTH STAR VISION: FROM DETERMINISTIC TO COGNITIVE SYSTEMS	5
3. USER EXPERIENCE LAYER: THE COGNITIVE INTERFACE	6
4. PROCESS LAYER: THE BRIDGE BETWEEN THE DETERMINISTIC AND AGENTIC PATHS	8
4.1 Application and Agents	9
5. FOUNDATION LAYER: THE INTELLIGENT CORE OF PROCESS AND DATA	11
5.1 AI Foundation	11
5.2 Data & Knowledge	13
6. PLATFORM LAYER: THE ENGINE OF INNOVATION, SCALE, AND RESILIENCE	15
6.1 SAP Business Technology Platform	15
6.2 SAP BTP Application Foundation 	17
7. THE TRUSTED FABRIC: INTEGRATION, SECURITY, AND GOVERNANCE	19
7.1 Integration	19
7.2 Security	20
7.3 Governance and Compliance	22
8. ECOSYSTEM LAYER: THE MARKETPLACE FOR AGENTS, TOOLS, AND EXTENSIONS	23
9. THE RESILIENT CLOUD: GLOBAL DELIVERY AND INTELLIGENT OPERATIONS	24
9.1 Global Availability and Rollout Strategy	24
9.2 Cloud Delivery and Operations	25
10. FUTURE PILLAR: ARCHITECTING FOR THE QUANTUM ERA	27
OPERATIONALISING THE NORTH STAR: FROM VISION TO GOVERNANCE	28
CLOSING NOTE: THE PATH FORWARD TO THE AI-NATIVE ENTERPRISE	28
ACKNOWLEDGEMENTS	28
GLOSSARY	28

1. EXECUTIVE SUMMARY
Technology is rapidly advancing, reshaping customer and shareholder expectations. Enterprises now expect systems to be intelligent, intuitive, and seamlessly interconnected across their value chains. Meeting these expectations requires a fundamental shift in how we design experiences, orchestrate processes, integrate data, and build the technology foundations that blend intelligence with resilience. 

To realise this shift and capture AI’s full potential, we must move from AI-first features to an AI-native model. AI-first prioritizes adding intelligence to existing functions, while AI-native embeds intelligence into the workflow itself, with reasoning and learning loops that use data and feedback to adapt continuously. As Sapphire Ventures notes, AI-native applications learn from diverse datasets, improve through continuous feedback, and deliver superior speed, scale, and cost, blending proprietary assets with fine-tuned models. To remain successful and relevant, this approach must become part of SAP’s architectural DNA alongside our proven deterministic systems.




Industry is converging toward large-scale agentic platforms built on distributed AI-native architectures. These systems rely on strong orchestration across models, agents, and services, persistent shared context, distributed data access, observability and high-performance compute. Market research reinforces this direction. Customers value SAP’s trusted processes and resilient systems, but they also expect acceleration. The choice is clear: Either we disrupt ourselves, or we risk being disrupted.

Leading the Next Era of Enterprise Applications. 
SAP’s opportunity lies not in simply adding AI features but in creating a Cognitive Core , an intelligence layer where SAP’s business data, process knowledge, and reasoning models come together so enterprise systems can learn and adapt. Built on the world’s richest business data and the deepest understanding of business processes, this core will power AI-native systems where workflows learn and adapt. The Cognitive Core brings together fast, intuitive System 1 style intelligence in the inner loop with deliberate, analytical System 2 style reasoning in the outer loop, a framing originally proposed by Daniel Kahneman in Thinking Fast and Slow. Meta-learning enhances this further by improving not just what systems know, but how they learn.
Within this foundation, autonomous agents manage tasks proactively, responding to changing contexts in adaptive and hyper-personalized ways. Every decision and outcome remains anchored in governance, symbolic reasoning, and human oversight, ensuring that as intelligence advances, trust deepens. This synthesis of intelligence and responsibility positions SAP to lead the next era of AI-native enterprise software, an evolution further articulated in SaaS Is Not Dead: It's Evolving, which explains how SAP’s SaaS foundation enables and accelerates the agentic AI future.

North Star Architecture: The Fabric Weaving Deterministic and AI Native Paths to lead the Next Era of Enterprise Software

SAP’s strategic response to the AI era is the AI-Native North Star Architecture, an integrated blueprint that embeds cognition and intelligence at the core of our portfolio. It builds on the Deterministic Path of suite harmonization, compliance, and reliability, extending it with an AI-Native Path characterized by adaptability, reasoning, and self-learning. Together, these paths define how SAP will deliver trusted intelligence at scale, uniting stability with innovation. To realize this evolution, we are reimagining three layers: User Experience (Joule Everywhere), Process (Joule Agents), and Foundation, which provides an AI operating system combining a data layer and an AI layer. All of this runs on a reimagined platform with Application Foundation that elevates the developer experience, unifies extensibility, simplifies integration, and accelerates innovation across the suite.
Cross-cutting SAP-managed suite harmonization qualities, such as integration, identity, extensibility, and observability ensure that intelligence remains reliable, explainable, and secure across every layer of the architecture. These qualities are not static principles, but operational mechanisms realized through policy enforcement, runtime governance, and continuous observability built directly into the Application Foundation and its underlying infrastructure. The architecture embodies a shift-left and shift-down approach, where resilience, compliance, and performance are delivered automatically by the platform. AI-native capabilities further extend this model, using agents that analyze and improve code, configurations, and runtime behavior to achieve these qualities without additional developer effort.
As the Cognitive Core matures, new horizons open: Context-engineered agents decide what to retrieve and why it matters; self-evolving agents refine reasoning through feedback; neuro-symbolic systems unite prediction with logic; and embodied AI carries SAP business logic into the physical world, transforming how work is orchestrated. These capabilities build on SAP’s neuro-symbolic approach, combining neural models such as LLMs for creative problem-solving with symbolic reasoning and structured workflows for compliance and accuracy.

Within this foundation, the Deterministic Path and the AI-Native Path operate as one. Data fuels intelligence, intelligence improves processes, and better processes generate richer data, compounding resilience, adaptability, and foresight. In this evolved landscape, users state intent such as “onboard a supplier” or “forecast inventory”. Joule interprets the intent, orchestrates the right actions, and delivers trusted outcomes. Each result feeds back into the foundation, creating a continuous learning loop that increases context and autonomy. This is progression, not replacement: Deterministic systems of record preserve reliability, while adaptive systems of intelligence add insight and foresight, making the enterprise more capable with every interaction.
Rich Sutton’s The Bitter Lesson reminds us that enduring progress in AI arises not from handcrafted rules but from systems that learn and scale with compute. SAP applies this lesson by pairing two complementary paths: The Deterministic Path, which safeguards trust and governance, and the AI Native Path, which uses learning systems that evolve with data and compute. Together they define the architecture for the AI-native era, where intelligence grows through experience and trust remains the foundation of every enterprise interaction.					[Back to TOC]

2. AI-NATIVE NORTH STAR VISION: FROM DETERMINISTIC TO COGNITIVE SYSTEMS 

The AI-Native North Star defines how SAP systems evolve from deterministic designs along the Golden Path to cognitive systems that can reason, learn, and adapt. It connects intelligence across the Experience, Process, Foundation, and Platform Layers, forming a coherent architecture where every element operates in context and contributes to continuous improvement.
  
At its essence, the AI-Native North Star establishes a unified model of intelligence across SAP’s ecosystem, with each layer playing a distinct role in this evolution:

User Experience Layer: Interactions become conversational, adaptive, and intuitive. Joule interprets user intent, draws on enterprise context, and orchestrates actions across applications, transforming routine workflows into intelligent, outcome-driven experiences.
Process Layer: Workflows shift from fixed logic to dynamic, goal-oriented coordination. Joule Agents plan, reason, and act across systems, continuously learning from feedback while maintaining the reliability and governance of deterministic processes.
Foundation Layer: Joule OS serves as the AI-native operating fabric that manages the lifecycle, orchestration, and governance of language models, agents, and AI services across the suite. Together with the SAP Business Data Cloud, SAP Knowledge Graph, and SAP HANA Cloud, they establish a unified semantic layer that grounds intelligence in trusted data. Integration, identity, and observability preserve compliance and trust as systems evolve.
Platform Layer: At the heart of SAP’s AI-native transformation lies the reimagined Platform Layer, where technology, data, and intelligence converge. It enables developers to innovate faster and operate with confidence by combining the power of SAP BTP and Application Foundation to deliver trusted, scalable intelligence across the enterprise.

Together, these layers create a continuous intelligence loop where data informs reasoning, reasoning drives action, and actions generate new data. This self-reinforcing  flywheel (Apps → Data → AI →Apps) strengthens with every interaction, enabling SAP systems to learn, adapt and improve continuously. By reimagining the stack, we accelerate our path towards a  truly AI-native enterprise software.


The AI-Native North Star Architecture redefines how work is designed, developed, and executed across the enterprise. From developers building extensions in vibe coding environments to analysts managing complex business processes.

How end user workflows evolve with AI-Native North Star Architecture
Today, users switch between multiple applications to verify data, follow up on issues, and complete business processes, with manual checks and cross-team coordination at every step. Under the AI Native North Star, this becomes a connected, outcome-first flow: a user states an intent in natural language, and Joule assembles the right data, context, and actions. Joule UX interprets the request, while Joule OS orchestrates agents that analyze information, suggest next steps, and automate execution. Behind the scenes, applications consume governed Data Products from the Business Data Cloud, enriched by the Knowledge Graph, and the Model Context Protocol links these foundations with Joule OS to create shared understanding across applications. At runtime, SAP and third-party agents collaborate through the A2A protocol so decisions and actions remain consistent across the enterprise. For example, in lead to cash a finance analyst who once toggled between Sales Cloud, S/4HANA, and Service Management can ask, “Show me high-value disputes likely to delay payment and suggest actions,” then receive prioritized cases, recommended steps, and automated follow-ups for approval. The result is fewer handoffs, faster outcomes with reduced DSO (Days Sales Outstanding), higher accuracy and trust, clear auditability, and a system that learns from every interaction.

Context engineering ensures that each agent receives the most relevant information within its reasoning window, while neuro-symbolic logic connects data patterns with business rules. The system returns a clear, unified view showing dispute causes, cash-flow risk, and recommended next steps such as credit adjustment, sales follow-up, or automated collection. Actions are executed through governed workflows managed within SAP’s trusted operational framework. Continuous feedback loops and telemetry ensure transparency, resilience, and smooth Day 2 operations, so that every resolution strengthens future recommendations. What once required hours of cross-system coordination now happens in one continuous SAP-managed process where finance, sales, and service collaborate seamlessly, transforming dispute management from reactive case handling into predictive cash-flow optimization.

Looking ahead: This vision sets the stage for the chapters that follow, marking the shift from deterministic systems defined by static logic to cognitive systems that can perceive, learn, reason and act. The guiding principles established here extend into all subsequent chapters, shaping how the architecture layers and cross-cutting capabilities come together to make the AI-native enterprise real. Together, they form a living architecture that evolves continuously while preserving the reliability and trust that define SAP.							[Back to TOC]
3. USER EXPERIENCE LAYER: THE COGNITIVE INTERFACE 
Lead author: Raman Sethi, Shashank | Contributors: Marcus Krug, Axel Schroeder, Lukasz Ostrowski 
| “Experience is the new interface, where intelligence becomes intuition”

Why a Unified Intelligent User Experience?
Our mission is to enable all SAP products to contribute to a seamless user experience (UX) that helps people get work done faster, make better decisions, and focus on outcomes rather than navigation. A unified intelligent UX transforms static, persona-based screens into dynamic, context-aware experiences that surface what matters most and guide users toward next best actions. This delivers tangible value to end users while ensuring that SAP applications remain integrated, consistent, intuitive, and cost-efficient to implement.
All products must comply with existing product standards, most prominently UX Consistency and Accessibility. The SAP design system must utilize adaptive design tokens that intelligently respond to diverse platforms and form factors – from phones and tablets to desktops and beyond. Rather than simply creating responsive interfaces, our applications must dynamically adapt to varying degrees of available screen real estate, optimizing functionality based on each device’s capabilities. Moving beyond manually coded screens, SAP needs to innovate with human-centred AI and create deeply personalized experiences. This requires building intelligent systems that learn user work patterns, generating user interfaces (UIs) and insights in real-time all while maintaining strict privacy boundaries and allowing user control over what is learned and shared. Finally, multimodal intelligence is crucial for the future of our applications, seamlessly blending voice, touch, gesture, and visual interfaces to help users interact in the most natural and effective way for their work.
 
The Existing User Experience Foundation 
The unified user experience rests on three foundational pillars that simplify design, development, and interaction across SAP’s portfolio. The ONE Design System addresses customer concerns about inconsistency by providing a unified design framework that consolidates existing guidelines and includes projects like Axpress, Vega, and Lyra for enhanced cross-product standards. SAP Kernel Services eliminates redundant development work by providing shared foundational services like navigation, notifications, and task management, enabling central entry points like SAP Start and SAP Build Work Zone. The UI Component Strategy expands reusable component libraries and transitions to an InnerSource model where teams collaborate on shared UI elements. Together, these pillars create a consistent foundation that simplifies both user interactions and development processes across SAP’s application suite. Please refer NSA 2024 document for more information.
  
How the User Experience Layer Is Architected
The User Experience Layer functions as the presentation and interaction tier of SAP’s AI-native architecture. It brings together design systems, runtime services, and adaptive intelligence into one coordinated framework. The design layer defines SAP’s common visual and interaction language through the Design System Portal. It standardizes design tokens, layout templates, and accessibility guidelines for web and mobile applications, ensuring predictable and inclusive design outcomes across the suite. We will significantly expand our component library to include intelligent and immersive UI components that address the future of work. Most embedded AI scenarios will require UI controls to ensure transparency, personalization, and safety in how the AI behaves and uses data. For example, productivity tools such as writing assistants or coding copilots need sliders or toggles to adjust creativity, tone, and response depth, while Joule workflows will benefit from confidence meters and “explain reasoning” views to maintain trust. The intelligence layer extends these interfaces with adaptive and conversational capabilities, embedding context-aware AI, voice support, and multimodal interaction patterns. Here, human-in-the-loop review mechanisms and live guidance features integrate directly into the user interface, ensuring that intelligence remains transparent and governed. Finally, the engagement layer delivers a personalized workspace where users interact with SAP intelligence through conversation, context, and insight. SAP Start and Joule Client provide a unified entry point to applications, workflows, and analytics, removing the need for traditional navigation. Embedded insights from SAP Analytics Cloud and the Business Answer Engine, in partnership with Perplexity, bring real-time visibility, while integration with SAP Signavio, LeanIX, and WalkMe adds process transparency, transformation management, and guided adoption. Together, these capabilities create a coherent and adaptive environment where users engage naturally with the SAP ecosystem. Together, these layers form an architecture that ensures SAP’s user experience remains consistent, extensible, and ready for intelligent adaptation across platforms and devices.
 
How the User Experience Layer will Evolve 
SAP is now extending this foundation toward the next generation of AI-powered, adaptive interfaces. The focus is to transform user interaction from static navigation to intelligent collaboration between users as well as between users and AI agents. The workflows can be system-triggered or user-initiated and can span multiple complex, interconnected tasks. In both scenarios, AI agents operate autonomously in the background and intelligently loop in humans only when critical decisions, approvals, or strategic input are required. 
The Conversational Core will evolve into a unified interface where users can interact with all SAP systems in natural language. It will progress beyond command execution toward multi-agent reasoning, delivering answers with clear source citations, supporting multimodal input through voice, text, images, and documents, and automating routine tasks while retaining context and memory across workflows. 
Gen UI dynamically creates user interfaces in real-time and on the fly, tailored to the specific needs of each user. Out of a business context Gen UI generates the most relevant experience, blending conversation and visual elements, with precision and personalized adaptation. This personalization is achieved through continuous learning of user preferences, contexts, and best practices.
The Voice AI capability will make SAP applications faster and more natural to use by enabling secure, context-aware voice interactions. It will be embedded as a kernel service, making it simple to adopt across applications.
Human-in-the-Loop Controls will ensure that AI agents remain governed and trustworthy. Review dialogs and approval checkpoints will be standardized as reusable UI components so that users can validate AI-generated actions before and after execution.
Live AI and Multimodal Interactions will empower field technicians with real-time assistance. By combining visual recognition with interactive guidance, SAP’s field applications will move from manual troubleshooting to step-by-step intelligent support, reducing downtime and improving productivity. Physical AI  will extend Joule into an interface for robots, unlocking humans focusing on strategic oversight & creative problem-solving.
Smart Glasses represent the next interface frontier. SAP’s design focus here will be on ambient awareness, delivering critical information at-a-glance without distracting users, ensuring SAP applications remain relevant as new computing platforms emerge.

Through these advancements, the User Experience Layer will evolve from a consistent interface into an adaptive, intelligent environment that learns from interaction, supports multiple modes of communication, and maintains SAP’s hallmark qualities of trust, reliability, and enterprise readiness. This evolution will blend human-to-human collaboration for sharing context and workflows, and agent-to-human collaboration where AI proactively assists users while maintaining human oversight and control.									[Back to TOC]

4. PROCESS LAYER: THE BRIDGE BETWEEN THE DETERMINISTIC AND AGENTIC PATHS
Lead author: Tim Back (Contributors: Shashank Mohan Jain, Jan Brunnert, Felix Sasaki, Marcus Krug)
| “From syntax to semantics, where logic meets intelligence and development becomes a unified craft”

4.1 Application and Agents 

SAP developers today build across two complementary paradigms: Deterministic applications and adaptive, agentic applications. For deterministic new business applications developers should continue to build using CAP, ABAP Cloud (RAP), Fiori UIs, SAP Business Technology Platform (SAP BTP) services, as these technologies ensure that the biggest number of cloud qualities, standards, functionalities as well as a high dev experience out of the box. This doesn’t mean that it is the only option to reach these qualities, and it also means that other existing application platforms that remain central to SAP’s portfolio. These platforms will evolve toward the SAP BTP as the SAP BTP Application Foundation (AppFND) evolves, using its SDKs and abstractions, ensuring a consistent development experience across both traditional and AI-native paradigms. Using in CAP / ABAP Cloud will automatically include these SDKs and abstractions.
 Adaptive applications, or better AI Agents can be developed as low code agents through environments such as Joule Studio or as pro code agents via Joule or the IDE of choice with popular agent frameworks, like Langgraph and CrewAI, but exposed as Agent-to-Agent (A2A) servers and registered with Joule. These introduce reasoning, goal-orientation, and self-learning capabilities into the business application world. Joule Studio for low code agents makes sure that agent intelligence can be developed, extended, and governed coherently, for pro code agents developer have to take care of some of these aspects by following the agent golden path rule set. The convergence of applications and AI agents following these rules ensures predictable enterprise qualities such as security, compliance, and reliability while introducing adaptability, reasoning, and automation.  .
 
Current Capabilities and Ongoing Development 
Developers when building new applications continue to build deterministic applications on the Golden Path using the SAP Build family including Build Code, Build Work Zone, low code and pro code agents and SAP BTP services. For detailed architecture and guidance, refer to the existing North Star 2024 Strategy document. For existing applications (i.e. not green- but brownfield) not based on the Golden Path or products that do not contain business applications (for example Signavio, LeanIX and WalkMe), using the evolving AppFnd SDKs and abstractions provide a good option to reach SAP overarching qualities, standards and functionalities. AppFnd provides the possibility to evolve in this direction making one step at a time.
Complementing this deterministic base, Joule Studio serves as the design-time environment mainly for low code agents. Here, developers define how agents reason, plan, and remember, while still reusing existing SAP business logic, data, and APIs. Joule Studio complements existing deterministic applications to extend them with intelligent agents, using agent skills and memory templates. ow code agents represent model-driven, low-code configurations built on the Business Agent Foundation (BAF), allowing rapid composition of cognitive workflows. 
Either using Joule Studio or any other development environment, developers can also create pro code agents following the golden path for agents described in the last chapter. They offer an approach that enables more flexibility, building on the very latest in the fast-changing AI agent world, deeper customization and richer reasoning. 
Both types, low code and pro code agents, run on a shared foundation for metering, telemetry, and LLM access through SAP AI Core. 
Any agent, whether low or pro code needs to publish metadata through Open Resource Discovery (ORD). ORD provides a standard protocol for exposing metadata about applications, agents, and data products. The Unified Metadata Service (UMS) aggregates this metadata, ensuring consistency, discoverability, and lifecycle visibility across SAP’s ecosystem. SAP Knowledge Graph consumes this metadata and provides it with additional context for AI capabilities, including a capability for scaling Joule orchestration, to Agents.
Low and pro code agents expose similar extension mechanisms for customers and partners. Crucially, SAP is ensuring that developers can move seamlessly between low-code and pro-code paradigms. A low code agent based on BAF needs to convertible into a pro code one without starting over, preserving investment and ensuring scalability as complexity grows.

How the Application and Agent Development Layer is Architected
The architecture of Application and Agent Development is structured into four coordinated layers that together bridge deterministic logic with adaptive intelligence. The Foundation Layer provides the deterministic backbone for SAP applications. This layer defines stable APIs and events that serve as the contract surface for higher layers (for example CAP and ABAP Cloud, where Foundation Layer will be built in automatically), ensuring that all adaptive systems operate within clear enterprise boundaries.

The Bridge Layer connects deterministic applications to agentic systems. It exposes existing business logic as discoverable capabilities through open protocols such as the Model Context Protocol (MCP) for tool invocation and the Agent-to-Agent  (A2A) protocol for multi-agent coordination. This bridge enables agents to use existing enterprise logic without modifying core applications, maintaining strict separation of concerns and governance. Current OCTO directives ensure that business data MCPs remain internal to SAP, while third-party MCPs are confined to external domains, preserving SAP’s data access and egress strategy. MCP servers are permitted for development, verification, and compliance tooling use cases but remain restricted for business data interfaces in accordance with SAP’s data access and egress policies. Since we can enrich internal MCP servers with additional context and security, SAP-built MCP servers will always be superior to MCP servers built by third parties on top of SAP systems; this approach significantly reduces risks to SAP’s core business, such as disintermediation, while offering customer benefits such as improved accuracy and governance.
  The Agentic Layer defines and orchestrates low- and pro-code agents. Agents consume SAP BDC Data Products and API endpoints from Lines-of-Business applications and publish metadata via the ORD protocol, which is aggregated by UMS for discoverability and for collaboration with other agents at runtime through the A2A protocol. Their execution is managed through SAP BTP and AI Core, ensuring secure hosting, monitoring, and compliance This layer extends deterministic systems with adaptive reasoning, planning, and decision-making while preserving enterprise control.

How It Will Evolve 
Future iterations of Joule Studio will introduce neuro-symbolic and policy-based extensions to improve reliability, explainability, and governance. Agents will gain the ability to decompose user intents into executable plans, validate outcomes using verifiers and policy engines, and combine probabilistic reasoning with rule-based logic to ensure compliance. The next evolution of this environment will be intent-based development, now being prototyped under Project Nova. Here, AI-assisted virtual solution architects interpret natural-language business requirements and automatically translate them into technical designs. A described business need is converted into a product-requirements document, refined by humans in the loop, and expanded into the required extension components like CAP services, Fiori UIs, workflows, or agents, that fulfil it. For example, a request such as “Create a custom leave-request application” could automatically generate a CAP and Fiori Elements app on SAP BTP, a corresponding approval process in Build Process Automation, and synchronization through the SAP S/4HANA Cloud Timesheet API. These prototypes illustrate the shift toward intent-driven solution design, where developers collaborate with intelligent systems that understand, reason, and assemble complete enterprise extensions.		[Back to TOC]

5. FOUNDATION LAYER: THE INTELLIGENT CORE OF PROCESS AND DATA 

5.1 AI Foundation
Lead author: Frank Feiks (Contributors: Shashank Mohan Jain, Jan Dumke, Felix Sasaki, Robin Dunst, Alex Schaefer, Marcus Krug)
| “AI is not an add-on; it is the operating system of the Business Suite”

Why AI Foundation?
Enterprise systems are evolving from systems of record to systems of intelligence. This requires a foundation that treats reasoning, context, and adaptability as core capabilities, not add-ons. AI Foundation provides that base, which orchestrates workflows, maintains shared context across agents and applications, and enables intelligent systems to operate natively inside enterprise processes with built-in guardrails for security, compliance, and governance. By combining Joule orchestration with SAP’s AI Core, SAP HANA Database Vector Engine, and SAP Knowledge Graph, AI Foundation creates a consistent environment for SAP’s cognitive core.  
 
Current Capabilities in AI Foundation and Ongoing Development 
AI Foundation powers SAP's cognitive core through capabilities that exist today, and others still evolving. It is expanding to integrate multiple layers and services: runtime, integration, semantic, reuse, and model services (LLMs). 

 In the runtime, the Joule Orchestrator assigns agents and tools to solve user requests. The runtime manages the lifecycle of no-Code agents, schedule their actions, integrates pro-code agents, and aligns execution with workflow goals, giving agents persistence and coordination.

For integration, the Agent and Tool Gateway and MCP Hub are being extended to connect AI agents securely to third-party or custom tools and provide governed access to SAP applications. 

For the Semantic layer, SAP Knowledge Graph and SAP HANA Database Vector Engine continue to advance in unifying structured data from systems such as SAP S/4HANA, SAP SuccessFactors, SAP Concur, and SAP Customer Experience with unstructured content, creating a harmonized context for reasoning.

For the Model Services (LLMs) layer, the generative AI hub in AI Core gives agents access to a suite of AI models and technologies, model training and grounding in customer data, to SAP-hosted language models, and to models in domains such as ABAP and tabular AI, which provides access to SAP Foundation Model (SAP RPT-1). It also provides grounding services and fine-tuning adapters that enable agents to reason and adapt within enterprise guardrails. These capabilities provide advanced optimization methods including prompt optimization or speculative decoding on self-hosted LLMs to align responses with enterprise semantics, test-time scaling to balance speed with depth of reasoning, and neural-guided search to keep exploration aligned with enterprise policies. 

Reuse layer, which standardizes and exposes reusable intelligence skills across the enterprise. This layer ensures that core cognitive capabilities like document understanding, tabular analysis, and visual inspection are implemented once and reused everywhere. Together, these layers form the AI-native foundation, where AI agents evolve beyond isolated transactions to operate with continuity, planning, and governance.

How AI Foundation Architects Intelligence 
AI Foundation embeds intelligence into enterprise systems through five core architectural responsibilities that ensure intelligence operates within the structure, safety, and reliability of SAP’s enterprise environment.

Coordinating Intelligent Agents: The architecture ensures that agents function as goal-directed participants in workflows rather than isolated scripts. It manages their integration, schedules their actions, and aligns execution with enterprise process models such as approvals, escalations, and dependency rules: always under governance constraints like authorization, thresholds, and audit requirements. 
 Engineering Context for Cognition: Large Language Models (LLMs) are stateless and need relevant context for optimal output. This turns context engineering into an optimization problem. AI Foundation addresses this through context engineering: assembling the right slice of enterprise information for each interaction. That means pulling in what’s relevant from prior exchanges, business semantics, and user roles- while filtering out redundant, outdated, or unauthorized data. Context engineering ensures that agents work with information that is accurate, sufficient, and compliant with enterprise rules.

Grounding Decisions in Enterprise Semantics: AI Foundation constrains retrieval and reasoning to SAP’s business semantics and data models. AI Foundation extends retrieval-augmented generation (RAG) into Agentic RAG, enabling agents to determine what to retrieve, when it is relevant, and how to apply it. This focuses reasoning on enterprise-consistent objects like ledgers, orders, or employee records and enforces governed rules like approval limits, policies, and compliance checks. Robotic semantics provide embodied AI agents with ability to understand the right physical actions to perform to achieve the business goals.

Ensuring Alignment and Safety: The architecture guarantees agent behaviour remains aligned and governed with enterprise goals. Decisions are limited to approved business rules, with embedded compliance checks at every step and fallback paths that handle uncertainty. As AI agents gain autonomy, safety mechanisms scale alongside them, ensuring every action is traceable to its source and maintaining control, accountability, and trust.
 Providing Reusable Intelligence Services: To avoid fragmentation, the architecture exposes shared intelligence services such as document understanding, tabular analysis, and visual inspection as composable skills. Standardized access through a common layer ensures consistent outcomes, reduces duplication, and makes intelligence reusable across applications.The architecture follows proven operating system principles: AI Agents function like processes, skills like libraries, orchestration like the scheduler, memory like shared address space, and gateways like device drivers. The unit of work shifts from processing transactions to executing reasoning steps.
 Evolution
The path forward extends beyond reinforcement learning. ﷟Meta-learning will enable agents to refine not just outputs but their own methods of learning. Together, these advances move toward what DeepMind calls the Era of Experience; meaning systems that evolve through ongoing interaction, turning workflows into cumulative assets that grow stronger with every cycle. This is also reflected in the work Meta is proposing for AI agents. . [Back to TOC]

5.2 Data & Knowledge
Lead author: Bernd Krannich (Contributors: Shashank Mohan Jain, Marcus Krug, Jeff Wootton, Felix Sasaki, Christoph Morgen, Sivakumar N, Priyanka Porwal)
| “When data connects through context, cognition emerges”
Why the Data & Knowledge Layer Is the Basis for SAP’s Data Architecture
Intelligent behavior requires both data and context. TG20 defines the boundary for SAP’s data architecture by standardizing on SAP HANA Cloud as the database technology and SAP Business Data Cloud (SAP BDC) as the common data-sharing platform. Through Data Products, curated and governed datasets described using  Open Resource Discovery (ORD), SAP BDC enables SAP, partners, and customers to share and consume business data securely and consistently. These data products are served through the Delta Sharing Protocol and, in the future, SQL APIs on a serverless compute layer; they form the foundation for analytics, planning, and AI across SAP’s portfolio.

What the Data & Knowledge Layer Delivers Today
SAP Business Data Cloud connects SAP and partner data in one governed landscape. SAP HANA Cloud provides compute and storage, including columnar tables, SAP HANA Data Lake Files, and the SAP Knowledge Graph Engine. BDC Foundation Services and BDC Connect manage connectivity, ingestion, orchestration, the lifecycle and exposure of Data Products. BDC Design Time Services offer modeling tools, catalog functions, and content lifecycle management, while BDC Cockpit and Data Product Studio serve as the unified administration and authoring environments. SAP Datasphere and SAP Analytics Cloud enable modeling, reporting, and planning. Integration with partners, starting with SAP Databricks and more recently SAP Snowflake, supports customer-facing data science environments. A Data Product Marketplace will provide a unified view of SAP and partner-built Data Products. These elements are detailed in the SAP BDC Target Architecture ACD.

The SAP Knowledge Graph (KG) provides contextual understanding for AI and analytics. It uses the SAP HANA Cloud Knowledge Graph Engine for storage and access to knowledge graph assets. Each capability links to a specific knowledge graph asset. For example, KG Reasoner connects to Datasphere metadata enabling agentic exploration of the model. The SAP Knowledge Graph is currently an external brand encompassing various knowledge graph assets and capabilities. The long-term goal is a single, technically and semantically connected Knowledge Graph supporting a broad variety of use cases.

Data Encryption, Data Protection and Privacy (DPP) ensure confidentiality, integrity, and compliance across hybrid landscapes. Encryption protects sensitive business and personal information at rest, in transit, and in use, reducing the impact of security threats. As AI and integration workloads grow, encryption must be embedded into data flows, APIs, and services. While personal data is processed for customers through transactions, analytics, or AI, SAP products must allow customers to operate in accordance with data-protection and data-residency regulations. The goal is to establish Data Protection and Privacy (DPP) standards for SAP product integrations based common DPP principles, in alignment with SAP DPP product-standard requirements. This harmonizes DPP capabilities across business processes through cross-consumable DPP features such as harmonized blocking and deletion provided by the Data Privacy Integration NextGen service (DPI) or automation based on Personal Data-annotations. SAP envisions a federated model for the creation, processing, transfer, and destruction of personal data across application boundaries, as described in the  vision on “Data Protection and Privacy”.
 How the Data & Knowledge Layer Becomes the Foundation for AI
Together, SAP HANA Cloud, SAP BDC, and the SAP Knowledge Graph together create a self-reinforcing flywheel. Line-of-Business applications generate data that is integrated and curated through SAP BDC and structured further through interconnected Knowledge Graphs. With customer consent, this data can train and validate models in the Customer Data Hub (CDH). AI Core performs inference, feeding results back into intelligent applications, which then generate new data and insights. This end-to-end flow is outlined in the work-in-progress ACD on CDH and SAP BDC Integration.

SAP HANA Cloud serves as the foundational data layer for Business AI. In addition to its core database function, it provides innovations for GenAI workloads: Vector Engine, Similarity Search, Text Embedding Models, and SAP HANA Cloud Knowledge Graph Engine. It also includes AI engines for embedded and custom applications. Predictive Analysis Library (PAL) and Automated Predictive Library (APL) enable large-scale, in-database inference, used for classic machine learning scenarios such as segmented time-series forecasting in Integrated Business Planning and Cloud ALM, where hundreds of thousands of forecasts are computed in parallel with in-memory performance.

The Customer Data Hub (CDH) provides a controlled environment for machine learning training. It extracts data from customer tenants, ensuring access only to verified parties. The Azure-based CPIT Development Environment offers a secure data-science space for Line-of-Business teams. Through SAP BDC, CDH gains access to all data products across SAP applications. These principles are captured in the ACD on CDH and SAP BDC Integration.

SAP BDC integrates with AI Core for inference of data as part of data products. The SAP BDC-BAI integration for Batch Inference in AI ADR specifies how AI Core retrieves data from SAP HANA Data Lake Files (HDLFS) and writes inference results back.

SAP Knowledge Graph (KG) serves as the grounding mechanism for AI, linking natural-language inputs to SAP’s structured metadata while reducing hallucinations. It connects reference metadata — such as API definitions, data models, and semantic information, accessible using Open Resource Discovery (ORD) and aggregated by Universal Metadata Service (UMS) with business-process and analytics content from SAP Datasphere. Customer-specific, tenant-aware extensions of the KG allow to enhance the SAP-managed metadata content.

Agentic AI and the Role of the Data & Knowledge Layer
SAP BDC and the SAP Knowledge Graph form the foundation of SAP’s agentic architecture. Once Data Products are modeled and structured through SAP Knowledge Graph, they can be exposed as AI tools to Line-of-Business agents using the Model Context Protocol (MCP). To support this, SAP BDC will introduce a serverless compute layer allowing agents to perform analytics and reasoning without direct file access. This evolution is described in the Business Data Cloud Agentic Capabilities vision.
Business Data Agents (BDAs) are specialized AI agents aligned to specific business processes and their corresponding Data Products. Each BDA provides governed, read-only access, preserving user permissions. BDAs collaborate through Agent-to-Agent (A2A) integration and can use few-shot learning to improve accuracy. They unify SAP and non-SAP data for business-aware reasoning, workflow orchestration, and continuous learning.
Joule, SAP’s “agent of agents”, uses both SAP BDC and SAP Knowledge Graph to provide context for intelligent actions. Within SAP BDC, Joule accesses analytical views modeled on Data Products and applies AI to enrich them. As input to Joule orchestration, SAP Knowledge Graph helps Joule discover the correct APIs and provides semantic grounding for query generation. Together, BDC, the Knowledge Graph, and Joule create a multi-agent platform delivering intelligent, context-rich, and trusted AI at scale. 								[Back to TOC]

6. PLATFORM LAYER: THE ENGINE OF INNOVATION, SCALE, AND RESILIENCE

The Platform Layer is SAP’s reimagined base for the AI-Native North Star Architecture, unifying technology, data, and intelligence to drive innovation, scale, and trust across the suite. It improves the developer experience for building, integrating, and operating applications, and defines a Golden Path that works across both greenfield and brownfield environments without compromising enterprise-grade reliability

6.1 SAP Business Technology Platform
Lead author: Jan Brunnert (Contributors: Shashank Mohan Jain, PVN PavanKumar)
| “At the heart of the Business Suite lies a platform built for innovation, scale, and resilience”

The SAP Business Technology Platform (SAP BTP) forms the foundation of SAP’s AI-Native North Star Architecture, connecting applications, data, and ecosystems through a unified, intelligent fabric. It embodies SAP’s strategic priority to make SAP BTP the platform for SAP and its ecosystem, ensuring that every product, partner solution, and innovation runs on a common, enterprise-grade foundation.
SAP BTP provides the technical base for SAP’s LoBs, customers, and partners, re-platforming major SaaS solutions like SAP Ariba Procurement and SAP Business Network onto a unified foundation. This transition simplifies integration, enhances user experience, and reduces total cost of ownership (TCO) and development (TCD) by consolidating capabilities across the suite. With proven scalability, SAP BTP supports millions of tenants globally, delivering the reliability, performance, and security required for SAP’s enterprise scale.

Service-Centric
SAP BTP follows a service-centric architecture, offering composable services, runtimes, and capabilities contributed by teams across SAP and bundled into cohesive, customer-facing offerings. Core capabilities include data management, application development frameworks, UI and integration technologies, security and compliance services, and commercial and lifecycle management.

SAP BTP has evolved from a runtime-centric platform to a multi-cloud, service-oriented, and open ecosystem. Most capabilities are independent of underlying runtimes or infrastructure, enabling faster adaptation to emerging paradigms such as agentic runtimes. This modular design allows SAP to innovate quickly while maintaining enterprise consistency, compliance, and governance. SAP BTP operates as a unified technical platform across multiple hyperscalers and SAP’s own cloud infrastructure. Through Unified Services, it delivers a harmonized operational and commercial framework that powers all SAP-managed SaaS applications. Developers can use SAP BTP’s enterprise-grade services without changing their architecture, ensuring workload mobility and a consistent experience.
This flexibility also allows selective use of hyperscaler or third-party services when needed, maintaining a balance between openness and SAP-grade control. SAP BTP evolves deliberately, integrating new capabilities only after they meet maturity and security benchmarks. This ensures the platform maintains the enterprise qualities that define SAP: reliability, compliance, observability, and security, while adapting continuously to new workloads and innovations.

Enhancing the Customer and Ecosystem Experience
Enhancing the overall customer experience across SAP’s portfolio is a central objective. The goal is to provide a seamless SaaS suite experience where customers can operate across multiple SAP and partner applications as one coherent system. Within this model, SAP-managed SaaS solutions leverage SAP BTP’s integration services such as Master Data Integration (MDI), Event Hub, or CIG to enable end-to-end interoperability, or for example Task Center and Workzone to enable a common user experience. SAP BTP manages the automated provisioning and integration lifecycle for these SAP-managed solutions. Customers can adapt configurations to their specific business needs without needing to understand underlying SAP BTP concepts such as subaccounts or runtimes. This allows enterprises to focus on business processes while SAP ensures that technical operations, compliance, and lifecycle management are handled consistently and securely. The result is flexibility for customers combined with operational simplicity, trust, and coherence across the suite.

A vibrant partner ecosystem extends SAP’s innovation reach through industry-specific and complementary solutions. Through the SAP Build portfolio, partners can develop and deploy extensions on SAP BTP using low-code tools, frameworks such as CAP, and AI-based development capabilities. Unified Services provide the commercialization and lifecycle infrastructure, including metering, billing, and marketplace integration, enabling partners and independent software vendors (ISVs) to bring innovations directly to SAP customers. SAP BTP also lowers the entry barrier for partners by offering clear architectural guidance, standardized frameworks, and self-service tooling. Solutions built and hosted on SAP BTP gain native integration into SAP’s ecosystem, benefiting from the same qualities of security, scalability, and compliance that define SAP-managed applications. Even solutions that do not directly run on SAP BTP can still consume its enterprise-grade services to integrate seamlessly into the SAP landscape. This ecosystem approach makes SAP BTP more than a technology platform. It becomes a collaborative innovation fabric that connects SAP, partners, and customers through shared standards, reusable services, and unified governance. By providing a consistent experience across development, deployment, and operations, SAP BTP strengthens SAP’s position as the trusted backbone of the intelligent enterprise.


Golden Path, Enterprise Qualities, and AI-Native Enablement: 
The goal of application frameworks on the SAPBTP is for developers to focus on business logic and innovation while SAP BTP guarantees platform consistency and operational excellence. The Business Suite requires best practices for integrating BTP services and frameworks in a standardized architecture, ensuring every application inherits security, scalability, reliability, and compliance. SAP BTP provides the Golden Path blueprint for external and internal best-practice development in greenfield projects, and combines the key enterprise-grade BTP services into a coherent assembly. The App Foundation expands the Golden Path scope and provides additional innovations into the Golden Path to significantly increase productivity and developer experience, with a focus to address the needs of existing LoB applications, brownfield environments and to further streamline key topics like Application configuration or deployment.

Golden Path applications form the building blocks of the intelligent suite. They deliver consistent data models, harmonized APIs, and unified lifecycle management, reducing duplication and accelerating innovation. Developers can use CDS, Fiori/UI5, and CAP to create extensions following this architecture, supported by PaaS capabilities for connectivity, observability, and integration. Customer-facing APIs continue to expand, enabling faster automation and simplified integration across solutions and partners. BTP reinforces SAP’s commitment to data protection and regulatory compliance. It meets strict information security and privacy standards, including specialized requirements such as EU Access Only for sensitive industries. BTP operates in private and sovereign cloud environments, offering customers flexibility to meet jurisdictional and sector-specific mandates. Through BTP Kyma and Gardener, SAP enables AI and LLM workloads on managed Kubernetes clusters in customer or dedicated data centers.

BTP is evolving as the foundation for both deterministic and adaptive workloads. It preserves enterprise qualities of stability, reliability, compliance, and security while extending into AI-native architectures that support agentic runtimes, dynamic orchestration, and continuous learning. Its role is to ensure that intelligence introduced across SAP’s portfolio remains observable, governed, and verifiable, blending new capabilities seamlessly with proven enterprise operations.
BTP also applies AI within its own platform services to enhance both functional and non-functional quality. The BTP Agent, exposed through the Model Context Protocol (MCP), and AI-driven observability features use analytics to increase developer and operator productivity while maintaining system stability. Routine DevOps tasks are being automated by intelligent agents, improving efficiency across both Golden Path and AI-native workloads.

Ultimately, BTP’s evolution reflects SAP’s broader transformation into an AI-native enterprise platform. It connects deterministic systems of record with adaptive systems of intelligence through a shared foundation that is open, governed, and built for continuous learning. By combining architectural discipline with AI-driven adaptability, BTP ensures that innovation scales without compromising the enterprise qualities that define SAP.				[Back to TOC]

6.2 SAP BTP Application Foundation 
Lead author: Rui Nogueira 
| “At the core of creation lies a foundation that unites builders, intelligence, and innovation”
 Why BTP Application FoundationTo shape the Golden Path for use in brownfield use cases, BTP Application Foundation (AppFND) aims to provide LoB applications in the Business Suite with targeted innovations, to transform the developer experience. AppFND is designed to further reduce the total cost of development and ownership (TCD/TCO) while accelerating time-to-market across SAP's portfolio.

Establishing a Harmonized Development Foundation
To achieve its mission, AppFND is establishing a cohesive environment that simplifies the entire software development lifecycle for internal teams, reducing the need to navigate multiple tools and onboarding processes. 

AppFND aims to accelerate the developer experience with a range of tools and reusable assets. The BTP SDK provides clients for various programming languages that ease access to BTP services and handle the automatic setup of dependencies like the audit log service. An Extensibility Portal allows developers to add custom fields for document types like contracts and invoices. Productivity is further boosted through Reusable Business Services for common functions like Harmonized Document Management, Output Management, and Semantic Search, which LoBs can both consume and contribute to via a federated model that promotes collaboration and reduces duplication of effort.

All resources and components will be defined declaratively and be stored in the so called “App.yaml”. By being declarative, we abstract underlying details which allows us to improve and innovate while keeping the interface for the applications easy and stable. The “App.yaml” will be utilized in all phases of the application lifecycle to automate infrastructure deployment, application delivery, tenant provisioning, SAP-managed integration and content delivery. This choreography is provided by the deployment services – building on the existing (BTP) technologies like SAP Cloud Orchestrator, DwC, Content Operator etc. and newly built APIs by technology providers like BDC. 

This is complemented by a Security Toolkit that embeds security standards using "Golden images" and provides built-in vulnerability scans into the infrastructure setup and service access layers, ensuring a secure foundation from the start.

AppFND also ensures that applications built on this foundation integrate seamlessly into the broader SAP ecosystem. It provides predefined BDC Integration Templates and strengthens SAP-to-SAP integration with a Managed Gateway to support critical migrations, such as the Ariba-to-Nexus and BTP Neo to Cloud Foundry transitions. 

Finally, AppFND wraps these capabilities in a consistent layer of governance. This includes driving the adoption of OpenTelemetry (OTel) for unified observability with an emphasis on suite-wide KPI reporting as part of the Rhythm of Business (ROB) strategy. 

The Path to an AI-Native Foundation
Building on this groundwork, the vision for AppFND is to evolve into an intelligent foundation that embeds AI into every aspect of the development lifecycle. 

AppFND will support the building and deployment of enterprise-grade AI agents (SAP managed software, multi-tenancy support, etc..). Pilots are underway to enhance the SDK for agent creation, supported by a template-based architecture that will allow LoBs to rapidly build custom agents without deep technical expertise, with GTLC use cases leading this effort. This will enable next-gen solutions, such as an Autonomous Sourcing Architecture that combines SAP Ariba with Google Gemini’s AI without rebuilding core functionality and will be supported by a proposed AI-powered BTP Search Layer.

The developer experience itself will be transformed. AI assistants embedded in the SDK will offer contextual support for coding and service consumption, while AI-powered tools will assist with code migration to reduce downtime and optimize code efficiency. This vision extends to specialized agents, such as a Product Manager AI Agent designed to automate strategic tasks like idea intake, semester planning, PRD creation, and cross-LoB synergy analysis.			[Back to TOC]

7. THE TRUSTED FABRIC: INTEGRATION, SECURITY, AND GOVERNANCE

Trust remains the cornerstone of SAP’s leadership as systems learn and act autonomously. The Trusted Fabric unites security, governance, and integration to verify identity, ensure transparency, and maintain compliance. It transforms protection and oversight into a living system where every action is verifiable and every outcome accountable.
 
7.1 Integration
Lead author: Priyanka Porwal, Thomas Janke
| “Integration is the rhythm that keeps the Business Suite in sync”
Providing our customers with a seamlessly-integrated suite of products, the SAP Business Suite, remains our highest strategic objective. This is a fundamental prerequisite for delivering end-to-end business processes and for maximizing opportunities to cross-sell within our portfolio. This objective is realized by providing a true SaaS integration experience, distinguished by full automation, SAP-managed and operated landscapes, standardized integration patterns, shared suite harmonization qualities, well-defined and discoverable API, as well as aligned data-models across all suite offerings. 

Customers consistently indicate that SAP applications lack out-of-the-box integration capabilities and are difficult to integrate. The reality is that most integrations are still customer-managed, which means that customers or partners are required to set up, maintain and operate technical wiring between SAP applications – an effort that is complex, time-consuming, cost-intensive, and error-prone. While pre-packaged templates and integration best practices help accelerate customer-managed integration, the overall effort for customers is very high.

Automation and SAP-Managed landscapes
On our SaaS journey, shifting technical setup and landscape operations from customers (customer-managed) to SAP (automated and SAP-managed) are key enablers. The goal is to provide an out-of-the-box, seamlessly-integrated product suite (Suite-First) that supports all major business processes across both public and private cloud. Going forward, customers should only make business-focused integration choices, supported by smart defaults and recommendations from SAP. These decisions remain customer-managed, giving them flexibility to shape their business processes. The required technical implementation, for example, setting up trust, system configurations, and so on, will be automatically set up, fully managed, and operated by SAP. In a Suite context, this means that customers can manage capabilities, such as adding or removing products and integrations using SAP For Me, but are not exposed to their technical realization through SAP BTP accounts, service instances, subscriptions, and so on.

The clear separation between business and technical integration, an intent-driven approach to provisioning and integration, and full automation based on best practices and landscape blueprints are all facilitated by Unified Services. Once applications and services have been centrally registered (Unified Service Manager), their provisioning and integration can be orchestrated through Unified Services, independent of where and how they have been built. The target landscape (desired state) is defined by combining landscape blueprints, customer input and information about the actual as-is landscape (Unified Metadata Service) and is then described and stored declaratively as resources in a central repository (Unified Resource Manager). Later, operators will be triggered to translate the intent into real landscape changes, for example, creating integrations (Unified Customer Landscape). Standard interfaces such as the Service Provider Fulfillment Interface (SPFI) and the Service Provider Integration Interface (SPII) help to unify the different set of tools and APIs available today.

Standardized Integration Patterns
Integrating end-to-end business processes that span across heterogenous solution landscapes has long been one of the top strategic priorities. It’s also crucial to acknowledge that within SAP we have a lot of heterogeneity in adopting integration patterns and the corresponding SAP frameworks and technologies applicable for these patterns. A primary reason for this comes from the fact that our suite of solutions (and their corresponding integrations) has been ‘both’ a combination of organically grown solutions as well as acquired and enhanced products. Best practices for application integration provides guidance for integration patterns and SAP integration technologies.  
AI Powers Integration and Integration Powers AI
In the era of AI-powered innovations the composability that APIs provide are crucial to connect to real world of data, business applications and services. In hybrid landscapes, integration powers AI use cases by providing the composable, trusted data and APIs it relies on for automation. As the solutions evolve, enterprises and consumers often deal with a plethora of APIs - and AI brings its own additional asks for APIs. Traditional integrations are static, rigid, assisted with pre-built connectors and packages. They now need to evolve to be more dynamic, API-driven and AI-powered. Integration is thus shifting from connector driven to intelligence-driven. AI agents would dynamically determine the intent, generate workflows on demand, intelligently selecting and orchestrating the API calls.  AI agents don’t just consume APIs, they can enhance integration itself by learning from usage, improving API design, automating integration mappings, and predicting integration failures before they occur.  For more details on SAP positioning, please check agent-to-agent interoperability patterns and the agent integration patterns. 
A well-crafted AI powered integration strategy depends not only on robust and high-quality APIs following our SAP API Guidelines but also significantly relies on the quality of their metadata, as clear, machine-readable documentation (for example, OpenAPI specification) and discoverability, are essential to ensure seamless and highly automated integration.  

One Domain Model (ODM) 2.0 provides a shared vocabulary of terms and definitions that all applications and services need to follow, ensuring high quality of metadata for business objects and consistency across the ecosystem.

Open Resource Discovery (ORD) will continue to be the central protocol used by applications and services to describe their resources and capabilities in a consistent and standardized way across SAP. By providing access to metadata on APIs (OData, OpenAPI, MCP), events (AsyncAPI), business entity types, and data products, ORD supports both static documentations, such as in the Business Accelerator Hub, as well as dynamic use cases, such as tenant-specific configurations and runtime extensions in the SAP BTP. It facilitates the discovery of APIs through a central catalogue and enables automatic integration. ORD will also enable the SAP Business Knowledge Graph, discovery of Agents (A2A), MCP servers and their capabilities (tools, resources and prompts). The SAP API Guidelines must evolve to reflect the AI use cases (work in progress). This would include guidance on protocols (MCP, Overlay, Arazzo, UTCP) and how to enhance existing APIs for better AI consumption. Guidance on API protocols will be reflected in consumption components, for example, SAP Knowledge Graph in the context of Joule orchestration. The usage of central tools, such as the API Metadata Validator or the Adoption Monitor for validation, is complementary, thus ensuring quality and compliance of SAP APIs.									[Back to TOC]


7.2 Security
Lead author: Gerlinde Zibulski (Contributors: Siddhartha Rao, Michele Bezzi, Jan Brunnert)
| “The strength of the intelligent enterprise lies in the trust fabric woven to hold it together”

Why Security Matters
Protecting customers’ critical business data across cloud and on-premise environments has always been central to SAP’s mission. SAP has built a long-standing foundation of secure software development and security offerings, including but not limited to SAP BTP Cloud Identity Services, SAP BTP Key Management, SAP BTP Credential Store, SAP Identity Management, SAP Single Sign-On, SAP Enterprise Threat Detection, and SAP NetWeaver Code Vulnerability Analyzers.
Agentic AI introduces new categories of risk. Its ability to make autonomous decisions, access external tools, and coordinate across trust boundaries expands the attack surface and creates interaction-driven vulnerabilities. Multi-agent systems acting across organizations magnify these risks. Regulatory frameworks such as the U.S. AI Action Plan and EU AI Act now make AI security mandatory, emphasizing collaborative, shared-threat intelligence principles aligned with SAP’s architecture.
AI is also an ally: Intelligent agents can audit systems, perform authorization checks, detect vulnerabilities, and enforce compliance early in development, embedding a shift-left approach that prevents risks rather than reacting to them.

What the SAP Security Framework Provides
SAP’s Three-Tier AI Defense Architecture extends its proven security, identity, and runtime capabilities into a comprehensive framework designed to counter agentic threats while meeting global regulatory requirements. It unites foundational protection, agent oversight, and AI-driven automation to secure distributed, autonomous, and adaptive enterprise systems.
AI systems amplify familiar risks such as broad attack surfaces, distributed architectures, and multi-party supply chains, while introducing novel ones such as prompt injection, model extraction, and data poisoning during training or runtime. Since AI agents act autonomously at scale, their decisions can have cascading effects across critical business operations. SAP’s approach adapts zero-trust principles to these realities, ensuring consistent protection across cloud, edge, and on-premise environments.

Identity Management becomes more complex in multi-agent ecosystems where models, services, and processes require distinct credentials and dynamic authorizations. SAP enables policy-based authentication, adaptive credential lifecycles, and context-aware access control. Observability expands beyond logging to capture agent behavior, decision auditing, and anomaly detection.

The secure use of third-party AI components is another focus area. Modern AI systems often rely on external LLMs, agents, and tools accessed using the Model Context Protocol (MCP). SAP’s framework enforces rigorous vetting, encrypted channels, and strict isolation to prevent compromise propagation across interconnected systems.

Encryption, key management, and configuration controls are optimized for AI workloads that handle high volumes of sensitive data and maintain persistent states. Automated configuration validation and drift detection preserve security posture.

Data protection follows a privacy-preserving design. Modules such as the Data Protection and Anonymization component in SAP AI Core and SAP Data Privacy Integration apply anonymization and data masking to maintain compliance without compromising model performance.

Monocultures represent a new systemic risk. As organizations deploy similar AI models, shared vulnerabilities could lead to cross-enterprise compromise. SAP’s diverse, modular security architecture mitigates this concentration risk through isolation boundaries, policy variation, and continuous model validation.

Agentic coding introduces another frontier. Coding agents that assist in software development must adhere to security-aware guidelines, ensuring AI-generated code undergoes proper review and validation before deployment. SAP promotes new coding standards interpretable by AI agents to keep automated development aligned with enterprise security policy.

How the Three-Tier AI Defense Architecture Works
SAP implements security through a progressive three-tier defense model that integrates traditional controls, agent oversight, and AI-powered automation.

Tier 1: AI Security Mesh Foundation Layer establishes zero-trust authentication, authorization, and traffic inspection. It validates every entity, monitors LLM calls and tool usage, authorizes each action, and records every event for auditing. Core capabilities include secure gateways, mutual TLS with dynamic certificate rotation, zero-trust policy enforcement, and AI-specific threat prevention such as prompt injection detection, behavioral analytics, and software bill of materials verification.
The Agentic Identity and Access Management (AIAM) Framework governs non-human identities through cryptographically verifiable agent birth certificates, dynamic permission templates, and automated credential rotation. It integrates with SAP BTP Identity Authentication for federated identity management and applies behavioral identity validation for continuous authentication based on agent communication and resource usage patterns.

Tier 2: Agent Supervision Layer deploys deterministic control agents that monitor, sanitize, and authorize other AI agents. These supervisory agents enforce input validation, output filtering, anomaly detection, and human oversight. Advanced capabilities include emergent threat modeling, predictive defense updates, and proactive detection of novel attack patterns.

Tier 3: Core Security Agent Automation Layer uses specialized AI agents to scale and automate security operations. Identity Management Agents handle provisioning and contextual authorization, while Security and Compliance Agents perform continuous audits, risk assessment, and policy enforcement. Operations and Maintenance Agents manage identity synchronization, registry monitoring, and predictive maintenance. This layer embeds secure development best practices directly into AI-assisted workflows, ensuring AI-generated code is validated, reviewed, and compliant before release.

7.3 Governance and Compliance
Lead author: Svetoslav Manolov
A crucial aspect of building trust with customers and authorities is SAP's implementation of a comprehensive internal governance and compliance management system, adhering to well-established and widely accepted international standards such as ISO and NIST. In the business context of broader AI adoption, ensuring trust necessitates governing the internal use of AI and the provision of AI through SAP products and services. This is essential to maintain compliance with applicable regulations and contracts, while also empowering customers and partners to do the same.
SAP has established an AI Governance framework to ensure adherence to regulatory requirements and provides thorough training to enhance AI literacy among staff operating and using AI systems. Implementation guidance for the required technical and operational measures are being developed and will as much as possible be automated, ideally in the SAP BTP layer, minimizing the effort for the SaaS layer when the technical and operational standards are followed. Examples of these measures include:

Avoidance of General-Purpose AI Model Provision: SAP is not in the role of a general-purpose AI Model Provider or a downstream modifier of general-purpose AI Models. This means SAP does not design or train general-purpose AI Models (training compute is greater than 1023 FLOPs) for productive use, and SAP does not fine-tune or re-train general-purpose AI Models with compute resources exceeding one-third of the original model’s training compute. Should SAP decide to assume one of these roles, additional precautions will need to be implemented to ensure compliance with the corresponding stringent regulatory requirements.

Central AI Inventory: To facilitate effective governance, risk management, and compliance, SAP maintains centralized repositories for tracking all AI use cases and systems. Given their different purposes and risks, SAP maintains one repository and a corresponding compliance workflow for internally-used AI and another for AI provided as part of SAP products.

Risk Classification and Mitigation: All AI use cases and systems undergo risk classification. Systems classified as high-risk are required to implement additional operational and technical measures, including continuous risk management, human oversight, data governance, accuracy, post-market monitoring, and incident reporting. Implementation guidance, automation, and standardization on the platform level are to follow. Critical regulatory compliance processes like incident reporting and post-market monitoring, required by various regulations and legislations, are to be harmonized and aligned within a central implementation at SAP.

Third-Party Governance: SAP enforces strict governance over third parties such as suppliers, SolEx partners, and OEM partners. These entities are onboarded and continuously managed according to standard compliance and risk management processes, to fulfill SAP’s obligations for due diligence. They are required to fulfill their corresponding regulatory obligations through technical, operational, and legal measures.

Certification: SAP builds trust with customers and regulators by certifying AI compliance with international standards. A single, holistic AI Governance and Management System enables a shift-left approach, maximizing standardization and automation while reducing implementation and audit effort and optimizing the customer consumption. Additionally, SAP offers AI compliance support to its customers and partners, including instructions for use, CE marking, and other documents necessary to facilitate their AI compliance.

By adhering to these principles and practices, SAP ensures that the usage and provision of AI are not only innovative but also responsible and trustworthy.				[Back to TOC]

8. ECOSYSTEM LAYER: THE MARKETPLACE FOR AGENTS, TOOLS, AND EXTENSIONS
Lead author: Shashank Mohan Jain, PVN PavanKumar (Contributor: Łukasz Ostrowski)
| “An open marketplace where intelligence multiplies through connection and collaboration”

Why have an Ecosystem Layer
The AI-native enterprise depends on deep collaboration between data, intelligence, and extensions. To enable this, SAP’s Ecosystem Layer creates a unified environment where APIs, data products, agents, and tools can be discovered, connected, and reused. It weaves SAP’s technical marketplaces into a single fabric that drives innovation across products, partners, and industries while maintaining governance, security, and trust.

The Foundation: APIs, Tools, and Data Products
The Ecosystem Layer builds on three interoperable pillars. Firstly, API Hub (SAP Business Accelerator Hub) and Open Resource Discovery (ORD) serve as the marketplace and metadata bridge for APIs, events, and MCP-compliant tools. For more on ORD, refer to the Integration Chapter. Secondly, SAP Business Data Cloud (BDC) and its Data Product Marketplace deliver curated Data Products catalogued in the Accelerator Hub and managed through BDC Cockpit. For additional details, see the chapter. Thirdly, the SAP Knowledge Graph adds the semantic layer that enables large-scale data access and reasoning, as discussed in the same chapter.

Marketplace for Agents and Tools
Beyond these foundations, the Ecosystem Layer introduces a unified marketplace for intelligent components. Joule Agents, Business Data Agents, and domain agents are registered, versioned, and shared through A2A and MCP protocols, with metadata governed by UMS and related compliance frameworks. The LeanIX Agent Hub serves as the enterprise registry for these agents and MCP servers.  Alongside them, MCP-compliant tools such as retrievers, analyzers, connectors, and verifiers define input and output contracts and provenance for safe reuse. Developers can combine APIs, Data Products, and Agents into cognitive workflows that operate across SAP and partner systems. Looking ahead, ecosystem partners offering robotic perception and foundation models will enrich embodied AI agents and extend this marketplace further.

The Path Forward
The Ecosystem Layer transforms SAP from a suite of applications into a connected network of intelligence. ORD links API Hub, SAP BDC Marketplace, and Agent Registries into a seamless discovery fabric where data, tools, and reasoning interoperate. Developers, partners, and customers build with SAP, co-creating agents, models, and extensions that expand enterprise intelligence. The SAP Architecture Center connects these innovations through reference architectures and best practices. Through this living ecosystem, SAP amplifies innovation across every layer of the AI-Native North Star Architecture.								[Back to TOC]

9. THE RESILIENT CLOUD: GLOBAL DELIVERY AND INTELLIGENT OPERATIONS
An AI-native enterprise runs on an intelligent, resilient cloud that delivers reliable, scalable performance worldwide. Cloud delivery and operations provide a unified operating model across hyperscalers and SAP data centers, and global availability comes from a federated architecture that balances latency, compliance, and cost to meet enterprise-grade SLAs. With observability, predictive scaling, and AI-driven remediation, the platform anticipates disruptions and keeps mission-critical systems always-on, compliant, and continuously improving.

9.1 Global Availability and Rollout Strategy 
Lead author: Matthias Rosker (Contributors: Priyanka Porwal, Darwin Wijaya)
| “Global availability is the promise that keeps the Business Suite always within reach” 
In today’s digital landscape, SAP cloud solutions must meet diverse customer needs, comply with complex regulations, and deliver services efficiently worldwide. To achieve this, SAP uses a multi-tier deployment and operations strategy that maximizes reach, flexibility, security, and cost efficiency. This chapter outlines the foundational models and principles SAP uses to deploy its cloud services and explains how public, private, and sovereign clouds serve different industries and regions while ensuring compliance, resilience, and innovation.

SAP follows a global multi-tier Deployment and Operations Strategy to optimize the overall deployment footprint and TCO. Deployments can be categorized as:

Public Cloud
A shared, multi-tenant architecture that operates at economies of scale to deliver innovation quickly and at best TCO. It is the baseline deployment model for most customers. Delivery of Public Cloud solutions follows the 4+1 infrastructure strategy.

Sovereign Cloud
Delivers enhanced cloud capabilities for security-hardened, regulated, and (where applicable) classified workloads requiring strict regulatory, security, and confidentiality controls. It offers stronger sovereignty across data, operational, technical, and legal dimensions. Delivery follows the 4+1 infrastructure strategy in shared data-center facilities that meet sovereignty standards and regulations.

Sovereign Cloud Onsite (SCOS): Uses SAP Cloud Infrastructure (SCI) and SAP BTP to deliver sovereign-cloud capabilities inside customers’ data centers. Operations follow sovereign-cloud standards and are performed by local operations teams. All applications run on an isolated SCI and must not call or consume services from external hyperscalers or third parties. To accelerate deployment and scaling, operations and lifecycle management will be standardized and simplified, including a reduction in third-party tools.

Private Cloud
Delivers SAP-operated products in single-tenant models, giving customers individual control of systems and environments while still optimizing for efficient, standardized operational and architectural concepts. Private Cloud offers the highest flexibility in cloud delivery.

Continuously increasing data localization restrictions limit cross-regional delivery of cloud solutions. Our design principle is to keep customer business data within country borders where regulated and to clearly document exceptions to create transparency. This aligns with customer expectations, reduces delivery complexity, and future-proofs delivery in changing regulatory and geopolitical environments. It is also important to align SLOs and disaster-recovery expectations between service producers and consumers. Services can be consumed non-regional for TCO reasons as described in “Non-regional services: Implementation Options,” while still meeting the boundary conditions mentioned above.

In our Multi-Cloud Strategy, Public Cloud and Sovereign Cloud deployments follow the 4+1 infrastructure strategy globally. Sovereign Cloud Onsite targets SAP Cloud Infrastructure as the sole platform, whereas Private Cloud may offer selected additional infrastructure options beyond 4+1 (for example, IBM Cloud, StackIT, and potentially others).

Delivery from SAP-managed Cloud Infrastructure provides a hyperscaler-independent option for cloud products and must be a design consideration for solutions. It also enables delivery into Sovereign Cloud Onsite and future models such as SAP Cloud for Defence. For all deployment models, standardized software packaging, delivery, operations, and lifecycle management are required. Environments, tools, services, and applications used internally at SAP must be productized with sovereign-cloud requirements in mind.

High availability and resilience are critical for SAP cloud deployments supporting mission-critical workloads. For the most critical locations, long-distance multi-region disaster recovery is a target offering. BTP as the platform for SAP cloud solutions will provide core disaster-recovery capabilities. In-metro DR will serve as a fallback to fail over across short distances as an interim step or in smaller regions where long-distance in-country DR locations are not available.

Location Strategy and Geo Expansion
SAP delivers Public Cloud solutions from 18 countries as a baseline in 2025. The availability of SAP BTP as the strategic platform for SAP cloud products forms the basis for SAP’s cloud location strategy. Expansion into additional locations (country and infrastructure) will occur selectively after careful business-case evaluation and potential analysis. Delivery from new locations will be evaluated from a cross-product and Business Suite perspective.				[Back to TOC]

9.2 Cloud Delivery and Operations 
Lead author: Priyanka Porwal, Tanuj Sharma, Jan Brunnert
| “Cloud operations turn reliability into rhythm and resilience into readiness”

SAP solutions must be secure, reliable, scalable, and cost-optimized. SaaS delivery lets SAP and customers save costs by leveraging synergies, reusing services and infrastructure, but only if the following foundational requirements are met.

Resilience
Resilience is a key quality of a cloud product, covering both unplanned and planned outages. SaaS solutions usually come with a service level agreement (SLA) of around 99.9xx percent availability; for example, 99.99 percent translates to about unavailability of system for 8.6 seconds per day.

SAP has experienced outages due to the heterogeneous nature of the product landscape and varying levels of resilience, leading to business disruptions for customers. To address planned and unplanned outages, we are striving to:
	•	Define aligned and minimal downtime windows, ideally near zero downtime, across applications, platform, and infrastructure.
	•	Standardize resilience definitions and metrics, availability calculations, and criteria to classify features by business criticality, and standardize tooling such as backup and recovery, central failover tooling, and monitoring. 
	•	Establish a standardized “shift-left to platform” architecture with agreed patterns, technologies, and services such as SAP HANA Cloud.
	•	Implement architecture concepts and operational procedures that enable zero or near-zero downtime maintenance.

More details can be found here.

Portability
Cloud solutions must be portable across multiple infrastructure environments to allow flexibility in target and deployment model selection, including Sovereign Cloud on-site. Portability at tenant, system, and landscape level enables relocation of cloud workloads across infrastructure platforms and countries to balance capacities and optimize TCO.

SAP must be able to shift workloads quickly between cloud providers, including SAP Cloud Infrastructure, in response to market forces and to reduce the risk of vendor lock-in. Many SAP workloads cannot easily be shifted because they are designed to run only on a particular provider’s infrastructure or depend on specific platform services. The goal is to minimize dependency on cloud platform providers by shifting to SAP platform and hyperscaler-agnostic services like Gardener, SAP HANA Cloud, App Foundation (SDK, programming model, observability, and so on), and a curated, exchangeable set of platform services.

Elasticity
Elasticity is the ability of a SaaS or PaaS application or service to adjust capacity automatically with demand, minimizing idle cost while preserving peak load performance. It should be managed as a continuous loop of designing for efficiency, monitoring utilization and spend, and iteratively right-sizing.

We realize this by containerizing applications to enable fast start-up and fine-grained horizontal scaling, using Kyma or plain Kubernetes operated with Gardener, or alternatives such as Cloud Foundry or the ABAP Cloud Runtime that provide managed scaling and operational abstractions. Container runtime guidance is available through CDE-57R1 (previously TG57).

We recommend adopting a stateless programming model so workloads can elastically adjust to demand, externalizing state to managed databases, caches, and queues, and designing idempotent APIs. On the data tier, SAP HANA Cloud contributes to elasticity through built-in capabilities that adapt compute, memory, and storage to load and capacity requirements.

Open Component Model
We adopt the Open Component Model for software components to streamline compliance, deployment, and reporting. It is already used in Hyperspace, SAP SuccessFactors, Kyma, Steampunk, SAP Analytics Cloud, Apeiro projects, and more.

AI-enabled operations and support
AI-enabled infrastructure operations (AIOps) provide enhanced visibility and intelligence across infrastructure and application layers. Automated, continuous monitoring enables early detection of anomalies, predictive issue resolution, self-healing workflows and data-driven insights for capacity and performance optimization, to improve customer experience and reduce operational effort. This supports proactive incident management, reduces operational expenses, and minimizes manual intervention in routine maintenance tasks, for example by streamlining data center rollout with the help of AI. 

Customer Supportability for AI scenarios 
This requires clear documentation, explainability, debugging tools, and strong logging and tracing so that issues can be reproduced and resolved consistently. With these foundations, support teams can handle AI incidents confidently and independently, sustaining customer trust at scale. More details at AI Supportability for AI use cases. 

In this evolution, SAP Cloud ALM extends from application-centric operations to AI-aware operations, supporting customers with the tools, workflows, and insights required to operate AI scenarios reliably at scale. [Back to Overview]

****************TBD Observability Chapter will be updated after the CTO Circle discussion finalization. Planned for CW 43 **************					[Back to TOC]

10. FUTURE PILLAR: ARCHITECTING FOR THE QUANTUM ERA
Lead author: Carsten Polenz (Addl. Contributor: Shashank Mohan Jain, PVN PavanKumar)

Why Architect for the Quantum Era?
The AI-Native North Star Architecture prepares SAP for the next wave of computational paradigms such as Quantum Computing, which operates through superposition and entanglement to process probability amplitudes instead of discrete states. This represents a fundamental shift that enables exponential acceleration for optimization, simulation, and probabilistic inference. Although current NISQ devices remain constrained by decoherence and limited error correction, establishing quantum readiness today ensures SAP and its customers can adopt quantum acceleration as soon as it becomes enterprise practical.

How the North Star Architecture Integrates Quantum Computing
Quantum Computing extends rather than replaces classical and AI-native systems. Artificial Intelligence provides cognitive adaptability, while quantum computation contributes probabilistic depth for specialized problem classes. Together they form a continuum of intelligent and probabilistic computing that defines the next phase of enterprise architecture.

Architectural Principles for Quantum Integration
Quantum Co-Processor Model: Quantum Processing Units (QPUs) will function as mathematical co-processors. SAP applications will orchestrate workflows and selectively delegate complex optimization or simulation tasks to these processors, which will return classical results that reintegrate seamlessly into deterministic business processes.
Cloud-Native, Service-Oriented Integration: Given their hardware-dependent nature, QPUs will be accessed as secure cloud services through standardized APIs. This approach hides vendor complexity, ensures interoperability, and enables maintainable, scalable integration across quantum hardware ecosystems.
Scoped for Compute-Only, Non-Transactional Scenarios: Because the no-cloning theorem prevents replication of quantum states, quantum execution will remain confined to analytical and compute-only contexts such as planning, forecasting, and optimization, avoiding transactional operations that rely on consistent state replication.

Path Forward: A Quantum-Ready Enterprise
By codifying these principles, the North Star Architecture establishes a foundation for hybrid computation where classical determinism, AI-driven cognition, and quantum probability coexist within a governed enterprise framework. It also ensures quantum-resilient security through post-quantum cryptography, key management, and encryption integrated into the Trusted Fabric, aligning technological progress with enterprise trust and compliance.

OPERATIONALISING THE NORTH STAR: FROM VISION TO GOVERNANCE
Turning the AI-native vision into reality requires strong alignment, clear accountability, and scalable execution. At the center of this operating model is the CTO Circle, which brings together the Chief Technology Officer, Solution Area CTOs, and the Office of the CTO. The CTO Circle is responsible for aligning core architecture principles, reviewing key technology partnerships, making technological decisions that shape SAP’s direction, and ensuring the North Star Architecture continues to evolve to address future challenges.
Decisions from these sessions are documented as Architectural Decision Records (ADRs) ensuring transparency and traceability from strategy to execution. This vision is then operationalized at scale through CPA working groups, which translate strategy into consistent architectural outcomes across the organization. Similarly, CPA working groups also create outcomes, including vision and ADRs, which are shared with CTO Circle for feedback. The SAP Architecture Center, CPA Document Repository, and CPAConnect provide the collaborative backbone, connecting experts globally to share learnings, conduct governance reviews, and reuse proven patterns and best practices.
Finally, the Suite North Star ensures all solution areas evolve within a unified blueprint that balances harmonization with innovation. Together, these mechanisms form a cohesive governance fabric where strategic intent becomes architectural clarity, enabling consistent and scalable decisions across products, platforms, and geographies. The result is a living blueprint that will guide SAP’s next decade of AI-native transformation.						[Back to TOC]

CLOSING NOTE: THE PATH FORWARD TO THE AI-NATIVE ENTERPRISE
| “AI-Native is not about adding intelligence to software, but about making software itself intelligent”

Every Revolution in Technology Begins with a Shift in Imagination. 
The AI-native enterprise is the next shift – a cybernetic system where software, data, and people evolve together through continuous feedback and self-correction. It is neither a product nor a feature but an architecture of intelligence that turns every layer into a source of cognition and every interaction into a learning signal. The Experience learns from behavior, the Process adapts in real time, the Foundation reasons over context, and the Ecosystem grows through shared intelligence. This is not about adding AI to software but about reimagining software itself as a living, learning network that scales both trust and intelligence through its feedback loops.
At SAP, we are uniquely positioned to lead this change, turning decades of enterprise knowledge into the foundation for a new kind of intelligence that is reliable, transparent, and deeply human at its core. Together, these become the architecture of the future, intelligent by design, adaptive by nature, and guided by feedback as the essence of trust. That is the path to the AI-native enterprise.

ACKNOWLEDGEMENTS (To be updated post review) 
GLOSSARY (To be updated post review)
